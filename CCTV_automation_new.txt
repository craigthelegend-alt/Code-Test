import os
import shutil
import zipfile
import subprocess
import hashlib
import threading
import time
from tkinter import *
from tkinter import ttk
from datetime import datetime
from PIL import Image, ImageTk, ImageSequence
import random
import traceback
from collections import Counter

# ----------------------------
# CONFIGURATION
# ----------------------------
INTAKE_FOLDER = r"C:\Users\PSNI1\Desktop\Processing\Intake"
JOBS_ROOT = r"C:\Users\PSNI1\Desktop\Processing\Jobs"
ARCHIVE_ROOT = r"C:\Users\PSNI1\Desktop\Processing\Archive"
OUTPUT_FOLDER = r"H:\output"
COMBINED_LOG = r"C:\Users\PSNI1\Desktop\Processing\combined_log.csv"
ERROR_LOG = r"C:\Users\PSNI1\Desktop\Processing\ERROR_LOG.txt"
MAX_RETRIES = 3

FFMPEG_PATH = r"C:\Users\PSNI1\Desktop\ffmpeg\bin\ffmpeg.exe"

# GIF CONFIGURATION
GIF_PATH_WAITING = r"C:\Users\PSNI1\Documents\waiting.gif"
GIF_PATH_RUNNING = r"C:\Users\PSNI1\Documents\running.gif"
GIF_PATH_DONE = r"C:\Users\PSNI1\Documents\done.gif"

# Limits and extensions
MAX_OUTPUT_SIZE_GB = 2
MAX_CONCAT_SIZE_GB = 3.5
MAX_CONCAT_DURATION_SEC = 7200  # 2 hours

DOCUMENT_EXTENSIONS = (".doc", ".docx", ".pdf")
VIDEO_EXTENSIONS = [".mp4", ".avi", ".mov", ".wmv", ".mkv", ".flv", ".webm", ".m4v", ".mpeg", ".mpg", ".264", ".h264", ".ts", ".mts", ".dat", ".vob", ".rm", ".rmvb", ".ogg", ".3gp"]
AUDIO_EXTENSIONS = [".mp3", ".wav", ".aac", ".flac", ".m4a", ".wma", ".ogg", ".opus", ".amr"]
REASONS_TO_KEEP_EXTRACTED = ["Extraction Failure", "Conversion Failures"]
FLAIR_MESSAGES = [
    "Checking files for suspicious metadata...",
    "Applying the digital stamp of justice.",
    "Making sure those pixels behave.",
    "The CPU is warming up the coffee machine.",
    "Processing, please wait...",
    "Tidying up the OTHER folder.",
    "Re-encoding reality, one frame in time.",
    "Consulting the Hash Gods for approval...",
    "Don't panic! This is faster than manual labour.",
    "We are the digital janitors of evidence.",
    "Converting compressed sadness into shiny MP4.",
    "Verifying file integrity (it passed the vibe check).",
    "Engaging the GPU turbo boosters!",
    "Calculating the perfect aspect ratio...",
    "Confirming file paths with the system oracle...",
    "Decompressing the narrative, frame by frame...",
    "Cleaning up temporary conversion remnants..."
]

# ----------------------------
# GLOBAL STATE
# ----------------------------
processing_active = False
paused = False
stopped = False
processing_thread = None
job_queue = []
current_job_index = 0
current_subprocess = None
total_ops_processed = 0
total_time_spent = 0
eta_label = None
flair_label = None
held_jobs_list = []

# --- GIF GLOBALS ---
gif_frames = {}
current_gif_state = "WAITING"
gif_index = 0
show_done_until = 0

# ----------------------------
# GUI SETUP
# ----------------------------
root = Tk()
root.title("CCTV Automation (GPU Enabled)")
root.configure(bg="#2b2b2b")
root.geometry("1100x700")

# Layout Frames
left_frame = Frame(root, bg="#2b2b2b", padx=10, pady=10)
left_frame.pack(side=LEFT, fill=BOTH, expand=True)
right_frame = Frame(root, bg="#1c1c1c", width=350, padx=5, pady=5)
right_frame.pack(side=RIGHT, fill=Y)
right_frame.pack_propagate(False)

# GIF & Status
top_panel = Frame(left_frame, bg="#2b2b2b", pady=15)
top_panel.pack(fill=X)
gif_label = Label(top_panel, bg="#2b2b2b")
gif_label.pack(side=LEFT, padx=10)
status_frame = Frame(top_panel, bg="#2b2b2b")
status_frame.pack(side=LEFT, fill=X, expand=True, padx=10)

stage_label = Label(status_frame, text="Ready to Start", bg="#2b2b2b", fg="#00aaff", font=("Segoe UI", 16, "bold"))
stage_label.pack(anchor=W)
current_file_label = Label(status_frame, text="Waiting...", bg="#2b2b2b", fg="#cccccc", font=("Arial", 10))
current_file_label.pack(anchor=W)

# Progress bar
style = ttk.Style()
style.theme_use('clam')
style.configure("TProgressbar", troughcolor="#444444", background="#00aaff", thickness=20)
progress_bar = ttk.Progressbar(status_frame, orient="horizontal", length=400, mode="determinate")
progress_bar.pack(fill=X, pady=5)

# ETA
eta_label = Label(status_frame, text="ETA: N/A", bg="#2b2b2b", fg="#ffaa00", font=("Arial", 10, "italic"))
eta_label.pack(anchor=E, pady=(0, 5))
# Flair message
flair_label = Label(status_frame, text="", bg="#2b2b2b", fg="#99ff99", font=("Arial", 9, "italic"))
flair_label.pack(anchor=W, pady=(5, 0))

# Control Buttons
button_frame = Frame(left_frame, bg="#2b2b2b")
button_frame.pack(pady=10, fill=X)
start_btn = Button(button_frame, text="Start Processing", bg="#008000", fg="white", font=("Arial", 11, "bold"), width=15)
pause_btn = Button(button_frame, text="Pause", bg="#ffaa00", fg="black", font=("Arial", 11, "bold"), width=15, state=DISABLED)
stop_btn = Button(button_frame, text="Stop", bg="#cc0000", fg="white", font=("Arial", 11, "bold"), width=15, state=DISABLED)
start_btn.pack(side=LEFT, padx=5)
pause_btn.pack(side=LEFT, padx=5)
stop_btn.pack(side=LEFT, padx=5)

# Activity Log
log_label = Label(left_frame, text="Activity Log", bg="#2b2b2b", fg="#ffffff", font=("Arial", 10, "bold"))
log_label.pack(anchor=W, pady=(10, 0))
log_text = Text(left_frame, height=20, bg="#222222", fg="#00ff00", font=("Consolas", 10), state=DISABLED)
log_scroll = Scrollbar(left_frame, command=log_text.yview)
log_text.configure(yscrollcommand=log_scroll.set)
log_scroll.pack(side=RIGHT, fill=Y)
log_text.pack(side=LEFT, fill=BOTH, expand=True)

# Jobs requiring review
held_jobs_label = Label(right_frame, text="Jobs Requiring Review", bg="#1c1c1c", fg="#ffffff", font=("Arial", 12, "bold"))
held_jobs_label.pack(pady=(5, 0))
held_jobs_text = Text(right_frame, height=10, bg="#222222", fg="#ffaa00", font=("Consolas", 10), state=DISABLED, wrap=WORD)
held_jobs_scroll = Scrollbar(right_frame, command=held_jobs_text.yview)
held_jobs_text.config(yscrollcommand=held_jobs_scroll.set)
held_jobs_scroll.pack(side=RIGHT, fill=Y)
held_jobs_text.pack(side=TOP, fill=X, expand=False, padx=5, pady=(5, 10))

# Pending queue
queue_label = Label(right_frame, text="Pending Job Queue", bg="#1c1c1c", fg="#ffffff", font=("Arial", 12, "bold"))
queue_label.pack(pady=(10, 0))
queue_text = Text(right_frame, height=1, bg="#222222", fg="#f0f0f0", font=("Segoe UI", 10), state=DISABLED)
queue_scroll_q = Scrollbar(right_frame, command=queue_text.yview)
queue_text.config(yscrollcommand=queue_scroll_q.set)
queue_scroll_q.pack(side=RIGHT, fill=Y)
queue_text.pack(side=TOP, fill=BOTH, expand=True, padx=5, pady=(5, 5))

# ----------------------------
# Logging & UI functions
# ----------------------------
def log_activity_colored(message, log_type="INFO"):
    COLOR_MAP = {
        "JOB_START_END": "#00ffff",
        "SUCCESS": "#66ff66",
        "WARNING": "#ffaa00",
        "ERROR": "#ff0000",
        "INFO": "#cccccc"
    }
    def _update():
        timestamp = datetime.now().strftime("%H:%M:%S")
        tag_name = f"{log_type}_{datetime.now().timestamp()}"
        color = COLOR_MAP.get(log_type, COLOR_MAP["INFO"])
        log_text.config(state=NORMAL)
        log_text.insert(END, f"[{timestamp}] {message}\n", (tag_name,))
        log_text.tag_config(tag_name, foreground=color)
        log_text.see(END)
        log_text.config(state=DISABLED)
    root.after(0, _update)

def log_error(job_number, error_type, message):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_message = f"[{timestamp}] JOB: {job_number} | TYPE: {error_type} | MSG: {message}"
    with open(ERROR_LOG, "a", encoding="utf-8") as f:
        f.write(log_message + "\n")
    log_activity_colored(f"ERROR ({error_type}): {message}", "ERROR")

def update_held_jobs_ui():
    def _update():
        held_jobs_text.config(state=NORMAL)
        held_jobs_text.delete(1.0, END)
        if not held_jobs_list:
            held_jobs_text.insert(END, "No jobs currently require manual review.", "INFO")
            held_jobs_text.tag_config("INFO", foreground="#cccccc")
        else:
            for job_num, reason in held_jobs_list:
                held_jobs_text.insert(END, f"{job_num} - {reason}\n")
        held_jobs_text.config(state=DISABLED)
    root.after(0, _update)

def update_queue_ui():
    if queue_text is None: return
    def _update():
        queue_text.config(state=NORMAL)
        queue_text.delete(1.0, END)
        if not job_queue:
            queue_text.insert(END, "Queue is empty. Ready to scan Intake.", "INFO")
            queue_text.tag_config("INFO", foreground="#cccccc")
            queue_text.config(state=DISABLED)
            return
        for idx, (z, d) in enumerate(job_queue):
            if idx < current_job_index:
                color = "#66ff66"
            elif idx == current_job_index:
                color = "#00ffff"
            else:
                color = "#888888"
            job_name = os.path.basename(z)
            if not d:
                job_name += " [ID REQ. PENDING]"
            tag_name = f"q_{idx}"
            queue_text.insert(END, job_name + "\n", (tag_name,))
            queue_text.tag_config(tag_name, foreground=color)
        queue_text.config(state=DISABLED)
    root.after(0, _update)

def set_progress(val, max_val, label_text):
    def _update():
        progress_bar["maximum"] = max_val if max_val > 0 else 1
        progress_bar["value"] = val
        current_file_label.config(text=label_text)
    root.after(0, _update)

def set_stage_title(text):
    root.after(0, lambda: stage_label.config(text=text))

def update_eta(total_ops_remaining):
    global total_ops_processed, total_time_spent
    def format_seconds(s):
        if s is None or s < 0: return "N/A"
        s = int(s)
        hours = s // 3600
        minutes = (s % 3600) // 60
        seconds = s % 60
        if hours > 0:
            return f"{hours}h {minutes}m"
        elif minutes > 0:
            return f"{minutes}m {seconds}s"
        else:
            return f"{seconds}s"
    if total_ops_processed > 0 and total_time_spent > 0:
        rate = total_ops_processed / total_time_spent
        if rate > 0:
            estimated_seconds = total_ops_remaining / rate
            eta_string = format_seconds(estimated_seconds)
            root.after(0, lambda: eta_label.config(text=f"ETA: {eta_string}"))
            return
    root.after(0, lambda: eta_label.config(text="ETA: Calculating..."))

def cycle_flair():
    if processing_active and not paused:
        message = random.choice(FLAIR_MESSAGES)
        flair_label.config(text=f"*** {message} ***")
    elif not processing_active:
        flair_label.config(text="")
    root.after(7000, cycle_flair)

def check_id_flag_in_file(file_path):
    if not os.path.exists(file_path): return False
    ID_FLAG_HTML = "<h3>identification</h3><p>true</p>"
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read().lower()
            content_clean = "".join(content.split())
            if ID_FLAG_HTML in content_clean:
                log_activity_colored(f"Content check passed: Found ID flag in {os.path.basename(file_path)}.", "SUCCESS")
                return True
            else:
                log_activity_colored(f"No ID flag found in {os.path.basename(file_path)}.", "INFO")
                return False
    except Exception as e:
        log_activity_colored(f"ERROR reading file for ID check: {os.path.basename(file_path)} | {e}", "ERROR")
        return False

def write_job_report(job_folder, job_number, start_time, pre_hash, file_counts, conversion_log):
    report_path = os.path.join(job_folder, f"{job_number}_Report.txt")
    end_time = datetime.now()
    lines = [
        f"JOB REPORT: {job_number}",
        "="*50,
        f"Start Time: {start_time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"End Time:   {end_time.strftime('%Y-%m-%d %H:%M:%S')}",
        "-"*50,
        f"Pre-Conversion SHA256 (Zip): {pre_hash}",
        "-"*50,
        "EXTRACTED FILES SUMMARY:"
    ]
    if file_counts:
        for ext, count in file_counts.items():
            lines.append(f"  {ext.upper()}: {count}")
    else:
        lines.append("  No media files found.")
    lines.append("-"*50)
    lines.append("CONVERSION LOG:")
    if conversion_log:
        for entry in conversion_log:
            lines.append(entry)
    else:
        lines.append("  No conversions attempted.")
    lines.append("="*50)
    try:
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("\n".join(lines))
        log_activity_colored(f"Generated Job Report: {os.path.basename(report_path)}", "INFO")
        return True
    except Exception as e:
        log_error("N/A", "REPORT_WRITE_ERROR", f"Failed to write report for {job_number}: {e}")
        return False

def ensure_folder(path):
    if not os.path.exists(path):
        os.makedirs(path)
        log_activity_colored(f"Created folder: {os.path.basename(path)}", "INFO")

def compute_hashes(file_path):
    log_activity_colored(f"Computing hash for {os.path.basename(file_path)}...", "INFO")
    sha256 = hashlib.sha256()
    md5 = hashlib.md5()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256.update(chunk)
                md5.update(chunk)
        return sha256.hexdigest(), md5.hexdigest()
    except Exception as e:
        log_error("N/A", "HASH_FAILURE", f"Could not hash {file_path}: {e}")
        return "N/A", "N/A"

def extract_zip(zip_path, dest_folder, job_number):
    zips_to_process = [zip_path]
    processed_zips = set()
    initial_extraction_error = None
    while zips_to_process:
        current_zip = zips_to_process.pop(0)
        if current_zip in processed_zips:
            continue
        processed_zips.add(current_zip)
        extraction_success = False
        try:
            log_activity_colored(f"Extracting: {os.path.basename(current_zip)}", "INFO")
            with zipfile.ZipFile(current_zip, 'r') as zip_ref:
                zip_ref.extractall(dest_folder)
            extraction_success = True
        except Exception as e:
            log_error(job_number, "EXTRACTION_FAILURE", f"Error extracting {current_zip}: {e}")
            if current_zip == zip_path:
                initial_extraction_error = str(e)
        if extraction_success:
            if current_zip != zip_path:
                try:
                    os.remove(current_zip)
                    log_activity_colored(f"Deleted nested zip: {os.path.basename(current_zip)}", "INFO")
                except Exception as e:
                    log_error(job_number, "ZIP_CLEANUP", f"Failed to delete nested zip {current_zip}: {e}")
            for root_dir, _, files in os.walk(dest_folder):
                for f in files:
                    if f.lower().endswith(".zip"):
                        sub_zip = os.path.join(root_dir, f)
                        if sub_zip not in processed_zips and sub_zip not in zips_to_process:
                            zips_to_process.append(sub_zip)
                            log_activity_colored(f"Found nested zip: {f}, adding to queue.", "INFO")
    return initial_extraction_error

def convert_file(job_number, input_file, output_folder, failed_files):
    global current_subprocess
    base_name = os.path.splitext(os.path.basename(input_file))[0]
    temp_output_file = os.path.join(output_folder, base_name + "_temp.mp4")
    log_activity_colored(f"Attempting GPU Encoding: {base_name}", "INFO")
    PRIMARY_CMD = [
        FFMPEG_PATH, "-i", input_file, "-c:v", "h264_nvenc", "-preset", "p4", "-rc", "vbr",
        "-cq", "26", "-c:a", "aac",
        "-vf", "scale=1920:1080:force_original_aspect_ratio=decrease,pad=1920:1080:(ow-iw)/2:(oh-ih)/2",
        temp_output_file, "-y"
    ]
    FALLBACK_CMD = [
        FFMPEG_PATH, "-i", input_file, "-c:v", "h264_nvenc", "-preset", "slow",
        "-b:v", "5M", "-c:a", "aac", temp_output_file, "-y"
    ]
    cmds_to_try = [PRIMARY_CMD, FALLBACK_CMD]
    conversion_success = False
    error_reason = ""
    startupinfo = subprocess.STARTUPINFO()
    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
    for attempt, cmd in enumerate(cmds_to_try):
        if attempt > 0:
            log_activity_colored(f"Retrying conversion with fallback command for: {base_name}", "WARNING")
        try:
            current_subprocess = subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, startupinfo=startupinfo)
            while current_subprocess.poll() is None:
                if stopped:
                    current_subprocess.terminate()
                    current_subprocess = None
                    if os.path.exists(temp_output_file): os.remove(temp_output_file)
                    return None, "N/A", "Stopped by user"
                time.sleep(0.1)
            if current_subprocess.returncode != 0:
                raise subprocess.CalledProcessError(current_subprocess.returncode, cmd)
            if not os.path.exists(temp_output_file) or os.path.getsize(temp_output_file) == 0:
                raise Exception("Output file missing or zero bytes.")
            post_sha256, _ = compute_hashes(temp_output_file)
            log_activity_colored(f"GPU Conversion Successful: {base_name}", "SUCCESS")
            conversion_success = True
            break
        except Exception as e:
            error_reason = str(e)
            log_error(job_number, "CONVERSION_ERROR", f"{base_name}: {error_reason}")
        finally:
            if not conversion_success and os.path.exists(temp_output_file):
                os.remove(temp_output_file)
            current_subprocess = None
    if conversion_success:
        return temp_output_file, post_sha256, None
    else:
        failed_files.append(os.path.basename(input_file))
        return None, "N/A", error_reason

def rename_and_check_dems(job_number, dems_folder):
    converted_files = []
    temp_files = [os.path.join(dems_folder, f) for f in os.listdir(dems_folder) if f.endswith("_temp.mp4")]
    temp_files.sort()
    for i, temp_path in enumerate(temp_files, 1):
        new_name = f"{job_number}_{i}.mp4"
        new_path = os.path.join(dems_folder, new_name)
        try:
            os.rename(temp_path, new_path)
            converted_files.append(new_path)
        except Exception as e:
            log_error(job_number, "RENAME_FAILURE", f"Failed to rename {os.path.basename(temp_path)} to {new_name}: {e}")
    final_video_outputs = [f for f in converted_files if f.lower().endswith(".mp4")]
    log_activity_colored(f"Renamed {len(final_video_outputs)} video outputs to {job_number}_[X].mp4", "INFO")
    return final_video_outputs

def get_video_duration(video_path):
    """Get video duration in seconds using ffprobe."""
    try:
        result = subprocess.run([
            FFMPEG_PATH.replace("ffmpeg.exe", "ffprobe.exe"),
            "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            video_path
        ], capture_output=True, text=True, check=True)
        return float(result.stdout.strip())
    except:
        return 0

def ai_video_check(video_path):
    """AI video quality check using OpenCV."""
    try:
        import cv2
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return False
        valid_frames = 0
        for _ in range(5):
            ret, frame = cap.read()
            if ret and frame is not None and frame.mean() > 5:
                valid_frames += 1
        cap.release()
        return valid_frames >= 3
    except ImportError:
        log_activity_colored("OpenCV not installed - skipping AI video check", "WARNING")
        return True
    except Exception as e:
        log_activity_colored(f"AI check error for {os.path.basename(video_path)}: {e}", "ERROR")
        return False

def concatenate_videos(job_number, video_paths, dems_folder):
    if len(video_paths) <= 1:
        return video_paths
    total_size_gb = sum(os.path.getsize(v) for v in video_paths) / (1024**3)
    if total_size_gb > MAX_CONCAT_SIZE_GB:
        log_activity_colored(f"Skipping concatenation: Total size {total_size_gb:.2f} GB exceeds limit", "WARNING")
        return video_paths
    total_duration = sum(get_video_duration(v) for v in video_paths)
    if total_duration > MAX_CONCAT_DURATION_SEC:
        log_activity_colored(f"Skipping concatenation: Total duration {total_duration/60:.1f} min exceeds limit", "WARNING")
        return video_paths
    concat_list_path = os.path.join(dems_folder, "concat_list.txt")
    try:
        with open(concat_list_path, "w") as f:
            for video_path in video_paths:
                escaped_path = video_path.replace("'", "'\\''")
                f.write(f"file '{escaped_path}'\n")
        final_concat_path = os.path.join(dems_folder, f"{job_number}_FINAL.mp4")
        log_activity_colored(f"Concatenating {len(video_paths)} videos...", "INFO")
        startupinfo = subprocess.STARTUPINFO()
        startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
        subprocess.run([
            FFMPEG_PATH,
            "-f", "concat",
            "-safe", "0",
            "-i", concat_list_path,
            "-c", "copy",
            final_concat_path,
            "-y"
        ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, startupinfo=startupinfo)
        if os.path.exists(concat_list_path):
            os.remove(concat_list_path)
        log_activity_colored(f"Videos concatenated into {os.path.basename(final_concat_path)}", "SUCCESS")
        return video_paths + [final_concat_path]
    except subprocess.CalledProcessError as e:
        log_error(job_number, "CONCATENATION_ERROR", f"Failed to concatenate videos: {e}")
        if os.path.exists(concat_list_path):
            os.remove(concat_list_path)
        return video_paths
    except Exception as e:
        log_error(job_number, "CONCATENATION_ERROR", f"Unexpected error: {e}")
        return video_paths

def copy_to_output(job_number, converted_video_paths):
    if not os.path.exists(OUTPUT_FOLDER):
        log_activity_colored("Output skipped: H:/output folder not found.", "WARNING")
        return False, "Output drive not available"
    # Look for FINAL file if it exists
    final_file = None
    for path in converted_video_paths:
        if "_FINAL.mp4" in path:
            final_file = path
            break
    # If no FINAL file and multiple videos, can't copy
    if not final_file and len(converted_video_paths) != 1:
        return False, "Multiple video outputs"
    converted_file = final_file if final_file else converted_video_paths[0]
    try:
        file_size_bytes = os.path.getsize(converted_file)
        file_size_gb = file_size_bytes / (1024**3)
        if file_size_gb > MAX_OUTPUT_SIZE_GB:
            return False, f"Oversized file ({file_size_gb:.2f} GB)"
        # Copy file
        shutil.copy2(converted_file, os.path.join(OUTPUT_FOLDER, os.path.basename(converted_file)))
        return True, ""
    except Exception as e:
        log_error(job_number, "OUTPUT_COPY_ERROR", f"Failed to copy to output: {e}")
        return False, str(e)

# ----------------------------
# Main Processing Function
# ----------------------------
def process_job(zip_file, doc_file):
    global paused, stopped, current_subprocess, total_ops_processed, total_time_spent, held_jobs_list
    job_number = os.path.splitext(os.path.basename(zip_file))[0]
    set_stage_title(f"Job: {job_number}")
    log_activity_colored(f"--- STARTING JOB {job_number} ---", "JOB_START_END")
    job_start_time = datetime.now()
    id_required = False
    can_proceed_with_extraction = True

    # Define folders
    job_folder = os.path.join(JOBS_ROOT, job_number)
    MASTER = os.path.join(job_folder, "MASTER")
    EXTRACTED = os.path.join(job_folder, "EXTRACTED")
    DEMS = os.path.join(job_folder, "DEMS")
    OTHER = os.path.join(job_folder, "OTHER")
    SUBMISSION = os.path.join(job_folder, "SUBMISSION")
    ID_STILLS = None
    folders = [MASTER, SUBMISSION, EXTRACTED, DEMS, OTHER]

    # Create folders
    for f in folders:
        ensure_folder(f)

    # Move zip
    try:
        dest_zip = os.path.join(MASTER, os.path.basename(zip_file))
        shutil.move(zip_file, dest_zip)
        log_activity_colored("Moved Zip to MASTER", "INFO")
    except Exception as e:
        log_error(job_number, "FILE_MOVE", f"Failed to move zip: {e}")
        return

    # Hash zip
    pre_sha256, md5 = compute_hashes(dest_zip)

    # Move submission doc
    doc_moved_path = None
    if doc_file:
        try:
            doc_name = os.path.basename(doc_file)
            doc_moved_path = os.path.join(SUBMISSION, doc_name)
            shutil.move(doc_file, doc_moved_path)
            log_activity_colored(f"Moved submission form: {doc_name}", "INFO")
        except Exception as e:
            log_error(job_number, "DOC_MOVE", f"Failed to move submission form: {e}")
            id_required = True
    else:
        id_required = True

    # Check ID flag
    if doc_moved_path and os.path.exists(doc_moved_path):
        if check_id_flag_in_file(doc_moved_path):
            id_required = True
        else:
            log_activity_colored("Submission document does NOT require additional Identification.", "SUCCESS")
            id_required = False

    # Handle ID requirement
    if id_required:
        log_activity_colored("!!! JOB MUST BE REVIEWED: Identification Required !!!", "WARNING")
        should_archive = False
        non_archival_reason = "ID Required"
        ID_STILLS = os.path.join(job_folder, "ID STILLS")
        ensure_folder(ID_STILLS)
    else:
        should_archive = True
        non_archival_reason = "Archived Successfully"

    # Extraction
    if can_proceed_with_extraction:
        error_extract = extract_zip(dest_zip, EXTRACTED, job_number)
        if error_extract:
            non_archival_reason = "Extraction Failure"
            can_proceed_with_extraction = False

    # Scan extracted files
    video_files = []
    audio_files = []
    other_files = []
    file_counts = Counter()
    processed_filenames = set()

    if can_proceed_with_extraction:
        for root_dir, _, files in os.walk(EXTRACTED):
            for f in files:
                fname_lower = f.lower()
                if fname_lower in processed_filenames:
                    continue
                processed_filenames.add(fname_lower)
                full_path = os.path.join(root_dir, f)
                ext = os.path.splitext(f)[1].lower()
                file_counts[ext] += 1
                if ext in VIDEO_EXTENSIONS:
                    video_files.append(full_path)
                elif ext in AUDIO_EXTENSIONS:
                    audio_files.append(full_path)
                else:
                    other_files.append(full_path)

        total_media_files = len(video_files) + len(audio_files)
        log_activity_colored(f"Found: {len(video_files)} Videos, {len(audio_files)} Audio, {len(other_files)} Other", "INFO")
        if total_media_files == 0:
            log_activity_colored("WARNING: No media files found in job.", "WARNING")
            if should_archive:
                should_archive = False
                non_archival_reason = "No Media Files Found"
            set_progress(0,1,"No media found")
        # Copy other files
        for f in other_files:
            try:
                shutil.copy2(f, os.path.join(OTHER, os.path.basename(f)))
            except:
                pass

        # Conversion
        if total_media_files > 0:
            total_ops_current_job = total_media_files
            current_op = 0
            failed_files = []

            for media_path in video_files + audio_files:
                while paused:
                    set_stage_title(f"PAUSED: {job_number}")
                    time.sleep(0.5)
                    if stopped:
                        return
                if stopped:
                    return
                current_op += 1
                is_video = media_path in video_files
                start_time = time.time()
                converted_file = None
                post_sha = "N/A"
                failure_reason = None

                if is_video:
                    set_progress(current_op, total_ops_current_job, f"Converting Video: {os.path.basename(media_path)}")
                    converted_file, post_sha, failure_reason = convert_file(job_number, media_path, DEMS, failed_files)
                else:
                    # Audio conversion
                    set_progress(current_op, total_ops_current_job, f"Converting Audio: {os.path.basename(media_path)}")
                    output_mp3 = os.path.join(DEMS, os.path.splitext(os.path.basename(media_path))[0] + "_temp.mp3")
                    startupinfo = subprocess.STARTUPINFO()
                    startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
                    success = False
                    for attempt in range(MAX_RETRIES):
                        try:
                            current_subprocess = subprocess.Popen(
                                [FFMPEG_PATH, "-i", media_path, "-b:a", "192k", output_mp3, "-y"],
                                stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, startupinfo=startupinfo
                            )
                            while current_subprocess.poll() is None:
                                if stopped:
                                    current_subprocess.terminate()
                                    current_subprocess = None
                                    if os.path.exists(output_mp3):
                                        os.remove(output_mp3)
                                    return
                                time.sleep(0.1)
                            if current_subprocess.returncode != 0:
                                raise subprocess.CalledProcessError(current_subprocess.returncode, media_path)
                            if os.path.exists(output_mp3) and os.path.getsize(output_mp3) > 0:
                                converted_file = output_mp3
                                post_sha, _ = compute_hashes(output_mp3)
                                success = True
                                break
                        except Exception as e:
                            failure_reason = str(e)
                            log_error(job_number, "AUDIO_FAILURE", f"Attempt {attempt+1}: {failure_reason}")
                        finally:
                            if not success and os.path.exists(output_mp3):
                                os.remove(output_mp3)
                            current_subprocess = None
                    if not success:
                        failed_files.append(os.path.basename(media_path))
                # Log post conversion
                if converted_file:
                    log_activity_colored(f"Post-conversion SHA256: {post_sha[:10]}...", "INFO")
                    total_ops_processed += 1
                    total_time_spent += (time.time() - start_time)
                else:
                    # failed
                    pass
                # Update ETA
                ops_remaining = (len(job_queue) - current_job_index - 1) * total_ops_current_job + (total_ops_current_job - current_op)
                update_eta(ops_remaining)
                if stopped:
                    return

            # Final renaming
            final_videos = rename_and_check_dems(job_number, DEMS)

            # Rename audio files
            temp_audio_files = [os.path.join(DEMS, f) for f in os.listdir(DEMS) if f.endswith("_temp.mp3")]
            temp_audio_files.sort()
            final_audio = []
            for i, temp_path in enumerate(temp_audio_files, 1):
                new_name = f"{job_number}_audio_{i}.mp3"
                new_path = os.path.join(DEMS, new_name)
                try:
                    os.rename(temp_path, new_path)
                    final_audio.append(new_path)
                except Exception as e:
                    log_error(job_number, "RENAME_FAILURE", f"Failed to rename {os.path.basename(temp_path)}: {e}")

            if final_audio:
                log_activity_colored(f"Renamed {len(final_audio)} audio outputs to {job_number}_audio_[X].mp3", "INFO")

            # Concatenate videos if multiple
            if len(final_videos) > 1:
                final_videos = concatenate_videos(job_number, final_videos, DEMS)

            # AI Video check
            for video in final_videos:
                if "_FINAL.mp4" in video or len(final_videos) == 1:
                    if not ai_video_check(video):
                        log_activity_colored(f"AI Video Check FAILED: {os.path.basename(video)}", "WARNING")
                        should_archive = False
                        non_archival_reason = "AI Video Check Failed"
                        break

            # Check for multiple outputs
            non_final_videos = [v for v in final_videos if "_FINAL.mp4" not in v]
            if should_archive and len(non_final_videos) > 1:
                should_archive = False
                non_archival_reason = "Multiple Video Outputs"
                log_activity_colored("!!! NON-ARCHIVAL: Multiple video outputs created.", "WARNING")

            # Copy final to output
            if should_archive and not id_required:
                copy_ok, reason = copy_to_output(job_number, final_videos)
                if not copy_ok:
                    should_archive = False
                    non_archival_reason = reason
                    log_activity_colored(f"!!! NON-ARCHIVAL: Output copy failed/oversized: {reason}", "WARNING")
            elif id_required and len(final_videos) > 0:
                log_activity_colored("Output copy skipped: Job requires Identification.", "WARNING")

    # ----------------------------
    # Final cleanup and archival
    # ----------------------------
    # Write report before moving
    write_job_report(job_folder, job_number, job_start_time, pre_sha256, file_counts, [])

    # Cleanup OTHER
    if os.path.exists(OTHER) and not os.listdir(OTHER):
        try:
            os.rmdir(OTHER)
        except:
            pass

    # Archive or hold
    if should_archive:
        # Archive
        try:
            if os.path.exists(EXTRACTED):
                shutil.rmtree(EXTRACTED)
                log_activity_colored("Deleted EXTRACTED folder (Job Archived).", "INFO")
            ensure_folder(ARCHIVE_ROOT)
            archive_path = os.path.join(ARCHIVE_ROOT, job_number)
            shutil.move(job_folder, archive_path)
            log_activity_colored(f"Job archived successfully to {os.path.basename(archive_path)}", "JOB_START_END")
        except Exception as e:
            log_error(job_number, "ARCHIVE_FAILURE", f"Failed to move job: {e}")
            non_archival_reason = "Final Archive Move Failed"
            held_jobs_list.append((job_number, non_archival_reason))
            update_held_jobs_ui()
        archived_status_str = "ARCHIVED"
    else:
        # Not archived, hold
        if os.path.exists(EXTRACTED):
            try:
                shutil.rmtree(EXTRACTED)
                log_activity_colored(f"Deleted EXTRACTED folder (Held: {non_archival_reason}).", "INFO")
            except:
                pass
        held_jobs_list.append((job_number, non_archival_reason))
        update_held_jobs_ui()
        log_activity_colored(f"Job folder remains in JOBS_ROOT (Reason: {non_archival_reason}).", "WARNING")
        archived_status_str = "HELD"

    # Final log entry
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    failed_count = 0  # You can track failed files if needed
    id_status = "TRUE" if not id_required else "FALSE"
    log_entry = f'{job_number},{os.path.basename(zip_file)},{timestamp},{id_status},{archived_status_str},"{non_archival_reason}",{len(video_files)},{len(audio_files)},{len(other_files)},{failed_count},{pre_sha256},{md5}'

    for attempt in range(MAX_RETRIES):
        try:
            with open(COMBINED_LOG, "a", encoding="utf-8") as f:
                f.write(log_entry + "\n")
            break
        except PermissionError:
            time.sleep(1)

    log_activity_colored(f"--- JOB {job_number} COMPLETE ---", "JOB_START_END")


# ----------------------------
# GIF Loader & Animator
# ----------------------------
def load_gifs():
    global gif_frames
    paths = {"WAITING": GIF_PATH_WAITING, "RUNNING": GIF_PATH_RUNNING, "DONE": GIF_PATH_DONE}
    for state, path in paths.items():
        try:
            img = Image.open(path)
            frames = [ImageTk.PhotoImage(frame.copy().resize((80,80))) for frame in ImageSequence.Iterator(img)]
            gif_frames[state] = frames
        except:
            gif_frames[state] = []

def animate_gif():
    global gif_index, current_gif_state, show_done_until
    if time.time() < show_done_until:
        state_key = "DONE"
    elif processing_active and not paused:
        state_key = "RUNNING"
    else:
        state_key = "WAITING"
    frames = gif_frames.get(state_key, [])
    if frames:
        gif_label.config(text="", image=frames[gif_index])
        gif_index = (gif_index + 1) % len(frames)
    else:
        gif_label.config(image='', text=f"{state_key} GIF N/A")
    root.after(100, animate_gif)

# ----------------------------
# Thread and Button Handlers
# ----------------------------
def run_queue_thread():
    global current_job_index, processing_active, stopped, total_ops_processed, total_time_spent, show_done_until
    processing_active = True
    total_ops_processed = 0
    total_time_spent = 0
    while current_job_index < len(job_queue):
        if stopped:
            break
        zip_file, doc_file = job_queue[current_job_index]
        update_queue_ui()
        try:
            process_job(zip_file, doc_file)
        except Exception as e:
            job_num = os.path.splitext(os.path.basename(zip_file))[0]
            log_activity_colored(f"CRITICAL ERROR on Job {job_num}: {e}", "ERROR")
            log_error(job_num, "UNCAUGHT_EXCEPTION", str(e) + "\n" + traceback.format_exc())
            held_jobs_list.append((job_num, "Script Crash/Error"))
            update_held_jobs_ui()
        current_job_index += 1
    update_queue_ui()
    update_held_jobs_ui()
    update_eta(0)
    if stopped:
        set_stage_title("Processing Stopped")
        processing_active = False
    else:
        set_stage_title("All Jobs Completed")
        log_activity_colored("All done, boss! Queue cleared.", "JOB_START_END")
        show_done_until = time.time() + 4
        processing_active = False
    set_progress(0,1,"Idle")
    root.after(0, lambda: start_btn.config(state=NORMAL, bg="#008000"))
    root.after(0, lambda: pause_btn.config(state=DISABLED))
    root.after(0, lambda: stop_btn.config(state=DISABLED))

def start_processing():
    global job_queue, stopped, processing_thread, current_job_index, held_jobs_list
    start_btn.config(state=DISABLED)
    pause_btn.config(state=NORMAL)
    stop_btn.config(state=NORMAL)
    job_queue = scan_intake()
    current_job_index = 0
    held_jobs_list = []
    update_held_jobs_ui()
    log_activity_colored(f"Queue loaded with {len(job_queue)} jobs.", "INFO")
    global stopped
    stopped = False
    update_queue_ui()
    processing_thread = threading.Thread(target=run_queue_thread, daemon=True)
    processing_thread.start()

def pause_resume():
    global paused
    paused = not paused
    if paused:
        pause_btn.config(text="Resume", bg="#00aaff")
        log_activity_colored("!!! PAUSED !!!", "WARNING")
        flair_label.config(text="*** PAUSED: Taking a quick breather... ***")
    else:
        pause_btn.config(text="Pause", bg="#ffaa00")
        log_activity_colored("!!! RESUMED !!!", "SUCCESS")

def stop_processing():
    global stopped, current_subprocess, processing_active
    stop_btn.config(state=DISABLED)
    pause_btn.config(state=DISABLED)
    stopped = True
    processing_active = False
    log_activity_colored("!!! STOP REQUESTED !!!", "ERROR")
    flair_label.config(text="*** STOPPING: Shutting down the digital engine... ***")
    if current_subprocess and current_subprocess.poll() is None:
        try:
            current_subprocess.terminate()
        except:
            pass
        current_subprocess = None

# Wire buttons
start_btn.config(command=start_processing)
pause_btn.config(command=pause_resume)
stop_btn.config(command=stop_processing)

# ----------------------------
# Initialization
# ----------------------------
load_gifs()
animate_gif()
cycle_flair()

# Ensure log files exist
if not os.path.exists(COMBINED_LOG):
    with open(COMBINED_LOG, "w", encoding="utf-8") as f:
        f.write("JobID,ZipName,Timestamp,ID_Required,Archived_Status,NonArchivalReason,VideoCount,AudioCount,OtherCount,FailedConversions,PreConversionSHA256,MD5\n")
if not os.path.exists(ERROR_LOG):
    with open(ERROR_LOG, "w", encoding="utf-8") as f:
        f.write("--- ERROR LOG INITIALIZED ---\n")

log_activity_colored("Ready when you are, chief.", "INFO")
update_held_jobs_ui()
update_queue_ui()

# Start GUI main loop
root.mainloop()